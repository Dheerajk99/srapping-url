{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3d82e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bcc9815",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'Amazon Scraping-Sheet1.csv'\n",
    "data = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe9a5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0234002",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcf4ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85725eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape product details from a given URL\n",
    "def scrape_product_details(url):\n",
    "    product_details = {}\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # Check if the product title element exists\n",
    "        title_element = soup.find('span', {'id': 'productTitle'})\n",
    "        if title_element:\n",
    "            product_details['URL'] = url\n",
    "            product_details['Title'] = title_element.get_text().strip()\n",
    "            \n",
    "            # Check if the image element exists\n",
    "            image_element = soup.find('img', {'id': 'landingImage'})\n",
    "            if image_element:\n",
    "                product_details['ImageURL'] = image_element['src']\n",
    "                \n",
    "            # Check if the price element exists\n",
    "            price_element = soup.find('span', {'id': 'priceblock_ourprice'})\n",
    "            if price_element:\n",
    "                product_details['Price'] = price_element.get_text().strip()\n",
    "            \n",
    "            # Check if the details element exists\n",
    "            details_element = soup.find('div', {'id': 'productDescription'})\n",
    "            if details_element:\n",
    "                product_details['Details'] = details_element.get_text().strip()\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        print(f\"404 Error: {url} not available\")\n",
    "        return None\n",
    "\n",
    "    return product_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb83ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ef3f13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 100/1000 URLs in 277.74 seconds\n",
      "Completed 200/1000 URLs in 279.12 seconds\n",
      "Completed 300/1000 URLs in 273.94 seconds\n",
      "Completed 400/1000 URLs in 128.79 seconds\n",
      "Completed 500/1000 URLs in 128.12 seconds\n",
      "Completed 600/1000 URLs in 224.38 seconds\n",
      "Completed 700/1000 URLs in 256.13 seconds\n",
      "Completed 800/1000 URLs in 91.71 seconds\n",
      "Completed 900/1000 URLs in 103.86 seconds\n",
      "Scraping completed. Data saved to C:\\Users\\Dheeraj/Desktop\\scraped_data.json\n"
     ]
    }
   ],
   "source": [
    "scraped_data = []\n",
    "\n",
    "# Loop through each row in the CSV and scrape product details\n",
    "batch_size = 100\n",
    "start_time = time.time()\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    if index > 0 and index % batch_size == 0:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Completed {index}/{len(data)} URLs in {elapsed_time:.2f} seconds\")\n",
    "        start_time = time.time()\n",
    "\n",
    "    country = row['country']\n",
    "    asin = row['Asin']\n",
    "    url = f\"https://www.amazon.{country}/dp/{asin}\"\n",
    "    product_data = scrape_product_details(url)\n",
    "    if product_data:\n",
    "        scraped_data.append(product_data)\n",
    "\n",
    "# Close the web driver\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "desktop_directory = os.path.expanduser(\"~/Desktop\")\n",
    "output_file_path = os.path.join(desktop_directory, 'scraped_data.json')\n",
    "\n",
    "output_file = 'scraped_data.json'\n",
    "with open(output_file, 'w') as json_file:\n",
    "    json.dump(scraped_data, json_file, indent=4)\n",
    "\n",
    "print(f\"Scraping completed. Data saved to {output_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3053dcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab6198f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212692c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f04588d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1edfed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836ebc15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7590148e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a50f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0860ce40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a35afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3366c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a7033e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a159b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b9af8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e2423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
